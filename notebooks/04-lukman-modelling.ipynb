{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Project settings"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64e96ad9fc4b6de2"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T19:34:56.436269700Z",
     "start_time": "2024-02-09T19:34:56.425953400Z"
    }
   },
   "id": "4de1adc03e8faa29"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'/mnt/d/Assignment/Skillvull'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# sys.pwd()\n",
    "os.chdir('../')\n",
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T19:34:56.475836500Z",
     "start_time": "2024-02-09T19:34:56.436269700Z"
    }
   },
   "id": "d12e6469f80aee20"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "project_path= os.getcwd()\n",
    "data_path= os.path.join(project_path,'data')\n",
    "src_folder= os.path.join(project_path,'src','models')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T19:34:56.553010400Z",
     "start_time": "2024-02-09T19:34:56.470649200Z"
    }
   },
   "id": "4527f0fa2618392"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb177083372409db"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "data= pd.read_pickle(os.path.join(data_path,\n",
    "                                  'processed',\n",
    "                                  'train.pickle'\n",
    "                                  )\n",
    "                     )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T16:28:29.628609400Z",
     "start_time": "2024-02-09T16:28:29.600118900Z"
    }
   },
   "id": "4676ee89dd7ba5ec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multilayer Perceptron\n",
    "feedforward artificial neural network that consists of fully connected neurons with a nonlinear kind of activation function, organized in at least three layers. It is notable for being able to distinguish data that is not linearly separable. The MLP is characterized by several layers of input nodes connected as a directed graph between the input and output layers. The algorithm is trained using the backpropagation method."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d0f10818dd314f4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optimization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16cdf3edfe7dee0b"
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "2024-02-10 01:11:29.949435: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\r\n",
      "2024-02-10 01:11:29.999809: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-02-10 01:11:29.999884: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-02-10 01:11:29.999926: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "2024-02-10 01:11:30.008316: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\r\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n",
      "2024-02-10 01:11:32.033089: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\r\n",
      "Your kernel may have been built without NUMA support.\r\n",
      "2024-02-10 01:11:32.063176: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\r\n",
      "Your kernel may have been built without NUMA support.\r\n",
      "2024-02-10 01:11:32.063261: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\r\n",
      "Your kernel may have been built without NUMA support.\r\n",
      "2024-02-10 01:11:32.065548: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\r\n",
      "Your kernel may have been built without NUMA support.\r\n",
      "2024-02-10 01:11:32.065596: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\r\n",
      "Your kernel may have been built without NUMA support.\r\n",
      "2024-02-10 01:11:32.065609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\r\n",
      "Your kernel may have been built without NUMA support.\r\n",
      "2024-02-10 01:11:32.798769: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\r\n",
      "Your kernel may have been built without NUMA support.\r\n",
      "2024-02-10 01:11:32.798843: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\r\n",
      "Your kernel may have been built without NUMA support.\r\n",
      "2024-02-10 01:11:32.798862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\r\n",
      "2024-02-10 01:11:32.798886: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\r\n",
      "Your kernel may have been built without NUMA support.\r\n",
      "2024-02-10 01:11:32.798907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1722 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\r\n",
      "Epoch 1/200\r\n",
      "2024-02-10 01:11:34.610914: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561f4360ce30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n",
      "2024-02-10 01:11:34.610958: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3070 Ti Laptop GPU, Compute Capability 8.6\r\n",
      "2024-02-10 01:11:34.614543: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\r\n",
      "2024-02-10 01:11:36.262527: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\r\n",
      "2024-02-10 01:11:36.346399: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\r\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fc1917833a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fc1917833a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\r\n",
      "10/10 [==============================] - 6s 236ms/step - loss: 5.7251 - auc: 0.5504 - val_loss: 19.6832 - val_auc: 0.5178\r\n",
      "Epoch 2/200\r\n",
      "10/10 [==============================] - 2s 178ms/step - loss: 5.2919 - auc: 0.6607 - val_loss: 13.9544 - val_auc: 0.5157\r\n",
      "Epoch 3/200\r\n",
      "10/10 [==============================] - 2s 171ms/step - loss: 5.1571 - auc: 0.7017 - val_loss: 10.8133 - val_auc: 0.5124\r\n",
      "Epoch 4/200\r\n",
      "10/10 [==============================] - 2s 161ms/step - loss: 4.8519 - auc: 0.7838 - val_loss: 9.2726 - val_auc: 0.5131\r\n",
      "Epoch 5/200\r\n",
      "10/10 [==============================] - 2s 166ms/step - loss: 4.7070 - auc: 0.8231 - val_loss: 8.2297 - val_auc: 0.5002\r\n",
      "Epoch 6/200\r\n",
      "10/10 [==============================] - 1s 157ms/step - loss: 4.5554 - auc: 0.8508 - val_loss: 7.7407 - val_auc: 0.5186\r\n",
      "Epoch 7/200\r\n",
      "10/10 [==============================] - 2s 188ms/step - loss: 4.4113 - auc: 0.8767 - val_loss: 7.5296 - val_auc: 0.5302\r\n",
      "Epoch 8/200\r\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 4.3317 - auc: 0.8862 - val_loss: 7.0109 - val_auc: 0.5430\r\n",
      "Epoch 9/200\r\n",
      "10/10 [==============================] - 2s 168ms/step - loss: 4.2360 - auc: 0.9014 - val_loss: 6.7764 - val_auc: 0.5387\r\n",
      "Epoch 10/200\r\n",
      "10/10 [==============================] - 2s 165ms/step - loss: 4.1937 - auc: 0.9001 - val_loss: 6.6568 - val_auc: 0.5588\r\n",
      "Epoch 11/200\r\n",
      "10/10 [==============================] - 2s 158ms/step - loss: 4.1168 - auc: 0.9097 - val_loss: 6.5977 - val_auc: 0.5332\r\n",
      "Epoch 12/200\r\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 4.0256 - auc: 0.9287 - val_loss: 6.4734 - val_auc: 0.5233\r\n",
      "Epoch 13/200\r\n",
      "10/10 [==============================] - 2s 178ms/step - loss: 3.9490 - auc: 0.9343 - val_loss: 6.4666 - val_auc: 0.5125\r\n",
      "Epoch 14/200\r\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 3.8884 - auc: 0.9413 - val_loss: 6.4105 - val_auc: 0.5084\r\n",
      "Epoch 15/200\r\n",
      "10/10 [==============================] - 2s 160ms/step - loss: 3.8198 - auc: 0.9477 - val_loss: 6.3731 - val_auc: 0.5130\r\n",
      "Epoch 16/200\r\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 3.8086 - auc: 0.9435 - val_loss: 6.2818 - val_auc: 0.4939\r\n",
      "Epoch 17/200\r\n",
      "10/10 [==============================] - 2s 162ms/step - loss: 3.7980 - auc: 0.9495 - val_loss: 6.2247 - val_auc: 0.4842\r\n",
      "Epoch 18/200\r\n",
      "10/10 [==============================] - 1s 157ms/step - loss: 3.7367 - auc: 0.9537 - val_loss: 6.1730 - val_auc: 0.4899\r\n",
      "Epoch 19/200\r\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 3.6467 - auc: 0.9580 - val_loss: 6.2781 - val_auc: 0.4540\r\n"
     ]
    }
   ],
   "source": [
    "! python {src_folder+'/mlp/train.py'}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T18:12:08.437522200Z",
     "start_time": "2024-02-09T18:11:28.962218200Z"
    }
   },
   "id": "6c9177775913976f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- The graph show that the accuracy keep increasing on training set (Indicated by decreasing loss)\n",
    "- The performance start converging at 19th epoch (Indicated by loss and metric)\n",
    "- AUC of validation set keep decreasing after 9th epoch"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e88927406cb0504"
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-4bbbbba9550681de\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-4bbbbba9550681de\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir {project_path+'/models/mlp/logs'}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T18:12:37.373573700Z",
     "start_time": "2024-02-09T18:12:37.320647100Z"
    }
   },
   "id": "1448f7b53101afb7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b36c42d1a94df451"
  },
  {
   "cell_type": "markdown",
   "source": [
    "From model optimization I found that:\n",
    "- The model perform nicely with AUC on level 0f 0.64\n",
    "- The accuracy is quite stable on train, validation, and test set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58f8108fe3eb29ef"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "2024-02-10 02:44:27.449397: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\r\n",
      "2024-02-10 02:44:27.489285: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-02-10 02:44:27.489349: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-02-10 02:44:27.489371: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "2024-02-10 02:44:27.494907: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\r\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n",
      "2024-02-10 02:44:30.495014: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\r\n",
      "Your kernel may have been built without NUMA support.\r\n",
      "2024-02-10 02:44:30.516820: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\r\n",
      "Your kernel may have been built without NUMA support.\r\n",
      "2024-02-10 02:44:30.516893: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\r\n",
      "Your kernel may have been built without NUMA support.\r\n",
      "2024-02-10 02:44:30.519174: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\r\n",
      "Your kernel may have been built without NUMA support.\r\n",
      "2024-02-10 02:44:30.519246: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\r\n",
      "Your kernel may have been built without NUMA support.\r\n",
      "2024-02-10 02:44:30.519262: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\r\n",
      "Your kernel may have been built without NUMA support.\r\n",
      "2024-02-10 02:44:31.176403: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\r\n",
      "Your kernel may have been built without NUMA support.\r\n",
      "2024-02-10 02:44:31.176504: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\r\n",
      "Your kernel may have been built without NUMA support.\r\n",
      "2024-02-10 02:44:31.176667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\r\n",
      "2024-02-10 02:44:31.176718: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\r\n",
      "Your kernel may have been built without NUMA support.\r\n",
      "2024-02-10 02:44:31.176773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5392 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\r\n",
      "10/10 [==============================] - 2s 2ms/step\r\n",
      "2/2 [==============================] - 0s 2ms/step\r\n",
      "5/5 [==============================] - 0s 2ms/step\r\n",
      "(313, 258)\r\n",
      "Test AUC: tf.Tensor(0.62624675, shape=(), dtype=float32)\r\n",
      "Validation AUC: tf.Tensor(0.6925042, shape=(), dtype=float32)\r\n",
      "Test AUC: tf.Tensor(0.62624675, shape=(), dtype=float32)\r\n"
     ]
    }
   ],
   "source": [
    "! python {src_folder+'/mlp/evaluation.py'}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T19:44:34.854612300Z",
     "start_time": "2024-02-09T19:44:25.921344800Z"
    }
   },
   "id": "3c4ba64933cd42d3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
